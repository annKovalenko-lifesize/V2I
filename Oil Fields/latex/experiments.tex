\section{Performance Evaluation}\label{experiments}
\subsection{Experimental Setup}
To evaluate the performance of our system we use a CloudSim simulation \cite{pe_2}. Cloudsim is a discrete event simulator that provides Cloud and Edge Computing models. In our simulation Edge Nodes are Data Center like devices with limited computational capacity (8 cores). Each core is utilized by one VM. All VMs in the Edge Node are homogeneous, i.e. have the same computational power (MIPS). On the other hand, a cloud server is a simulated Data Center with larger computational power (16 cores). We also implement the bandwidth for the Cloud Server and simulate the propagation delay to calculate the communication latency in our scenario. All these parameters are scalable. In this work, we implement a small scale simulation which can be scaled up in future work. 

In our simulation, we implement tasks as "cloudlets" with additional parameters added to the CloudSim's default configuration. We create 1 edge node and a coordinator component which allocates the tasks according to our proposed heuristic. 

\subsection{\textbf{Workloads}}
In our simulation, we randomly generate execution times using Gaussian distribution\cite{li2017resource}. We use results of the Extreme Scale System Center (ESSC) at Oak Ridge National Laboratory (ORNL)~\cite{khemka2015utility,KHEMKA201514} to implement the arrival time for each task. Nevertheless, the arrival time from this workbench is very sparse which is not applicable for our work. For this reason we generate dense arrival time by increasing the number of tasks (24000) compare to the workbench. Initially, every \pu~(Edge and Cloud)~is assigned an individual workload to create an oversubscription situation and to obtain historic estimated task completion times. Together with an individual workload, our receiving coordinator is assigned the major workload. This major workload is the one we consider for our results evaluation. The workloads are seeded and changed from trial to trial. By manipulating the number of tasks in the initial workloads, we are able to control the system's oversubscription level.

\subsection{Experiments}
To study the performance of our model thoroughly, we evaluate the system under various amounts of arriving tasks. We analyze the impact of the increasing workload on the oversubscribed system. Initially, each \pu~in the system has it's own workload and is proved to be oversubscribed (deadline miss rate of tasks is more than 20\%). Additionally, we assign a testing workload to the Edge Node which uses a coordinator to allocate them. The individual workload for each \pu is independent of the testing workload, as we assume the testing workload to be extra request bursts that can occur during the emergency situations. We consider the minimum testing workload to be a 700 tasks and the maximum to be a 18000 tasks. In each step, we increase the workload by a certain amount of tasks and account for the number of tasks that miss their deadline. For each step, we perform 10 trials and calculate the average number of tasks that miss the deadline. We compare the average number of tasks that miss their deadline while using certainty coordinator heuristic, task type heuristics and baseline heuristic. 

Figure 4 demonstrates the results obtained from the described experiments. The first image of figure 4 represents the results obtained using the FCFS scheduling algorithm. As we can see, the coordinator performs better using the certainty heuristic rather than baseline and task type heuristics. As certainty heuristic accounts for the deadline and tends to support real-time tasks even a slight improvement in the miss rate is good considering the lack of computational power in the edge. 


Only 17.01\% of all tasks of the whole system workload miss their deadlines using the certainty heuristic, where more than 22.20\% of the testing tasks miss their deadline with the baseline heuristic. Although the deadline miss rate grows with the increase of the workload for all three heuristics, the certainty heuristics performs better from the beginning to the midrange of the workload increase. From the midrange to the largest workload, certainty heuristic performs nearly the same as the other two heuristics.

We assume that the performance of the certainty heuristic depends on the level of the initial oversubscription of the system, but we leave finding the proof for our assumption for the future research. We can also notice that MR heuristic performs slightly better using the SJF scheduling rather than FCFS. The reason for that can be the efficient scheduling of short tasks first. Overall, we can observe that certainty heuristic performs better than task type and baseline heuristics, which can provide a better robustness for the whole system in the situations of oversubscription. 

