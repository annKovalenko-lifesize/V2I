\graphicspath{ {Figures/} }
\section{Approach}\label{approach}
According to the system model, tasks arrive at the PU randomly and the arrival rate is not known in advance. Receiving \pu~is considered to be oversubscribed, which means that it receives the number of tasks beyond its capacity to execute within a deadline. Therefore, some tasks are projected to miss their deadline. If such tasks are delay-sensitive, then they are dropped. Dropping tasks is a usual practice in oversubscribed real-time systems \cite{khemka2014utility,KHEMKA201514,khemka2015utility}. In such systems, the execution of a task that is going to miss its deadline has no value.

Here, we define the task robustness as the certainty of the task to meet its deadline in a particular \pu~(Edge or Cloud). For the arriving task of type ``i" in a \pu~j, the robustness can be defined as : 
\begin{equation} 
	C_j(t_i) = \delta_i - t_i^c
\end{equation}
where $\delta_i$ is the deadline of the task type and $t_i^c$ is the completion time of the task type ``i". Therefore, if the arriving task has a greater certainty to meet its deadline in the \pu (Edge Node) ``A" ($C_A(t_i)$) than in a \pu (Cloud Server) ``B", then the Edge Node ``A‚Äù provides a greater robustness for this task.

\subsubsection{\textbf{Delay Estimation}}
The calculation of the end-to-end delay of the task during the processing in a smart oil field can be defined as :
\begin{equation} 
    D_s = d_C + d_P
\end{equation}
where $d_C$ is a communication delay and $d_P$ is a processing delay. For the Edge Node a communication delay can be further broken down into  the average uplink($d_U$) delay and the average downlink($d_D$) delay. 

For the task $t_i$  requested by an application ``i" from the Edge Node ``m", the uplink delay is \begin{equation} d_\textrm{U} =  \frac{L_\textrm{i}}{R_i^m} \label{eq:2} \end{equation} and the downlink delay is \begin{equation} d_\textrm{D} =  \frac{L_\textrm{i}}{R_m^i} \label{eq:3} \end{equation} where $L_i$  is the task packet size, $R_i^m$ and $R_m^i$ is the transmission data rate for the link from ``i" to ``m" (uplink bandwidth) and from ``m" to ``i" (downlink bandwidth) respectively.

For the Cloud Server, we need to consider a propagation delay ($d_R$) when calculating a communication time. Satellite is used for transferring the task to the Cloud Server. Therefore, in this scenario, a propagation delay can be defined as : 
\begin{equation} 
    d_R = \frac{Distance}{Speed} * 2
\end{equation}
In the above equation, we consider a round trip time which is twice the delay. Therefore, communication delay for the Cloud Server consists of a transmission delay along with a propagation delay. As such, we define communication delay for  the Cloud Server as: 
\begin{equation} 
    d_C =  \frac{L_\textrm{i}}{R_i^m} +\frac{Distance}{Speed} * 2 + \frac{L_\textrm{i}}{R_m^i}
\end{equation}

Different applications request different jobs through the uplink channel from the \pu~. Upon request, the task first goes through the coordinator. The coordinator is the component that allocates arriving tasks to the appropriate \pu s. It makes the decision of task allocation, considering that its robustness must be maximized. As a reflection of this decision, the task is then transferred to the \pu~ that offers the highest robustness. The coordinator uses the average task completion time extracted from the historical data to calculate robustness of the task in the Edge Node. In case of the Cloud Server, the coordinator also incorporates the task transfer time(transmission delay \& propagation delay) for determining the robustness of task. This process also takes historical data into account for calculating the transfer time.

When coordinator gets the task $t_i$  of task type ``i", it calculates the deadline ($\delta_i^j$) of this task for the \pu s(edge node \& cloud). Then it calculates the certainty(C($t_i$)) of the task by deducting the completion time of that particular task from its deadline. The acquired difference indicates the time remaining before the deadline occurs. The higher the difference, the more chances the task has to meet its deadline. Therefore, coordinator checks the certainty of an arriving task both for the Edge Node and the Cloud Server. After all, the task is assigned to the \pu(Edge or Cloud) that provides the highest certainty.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{approach}
	\caption{A proposed model where the coordinator efficiently allocates arriving tasks}
\end{figure}

